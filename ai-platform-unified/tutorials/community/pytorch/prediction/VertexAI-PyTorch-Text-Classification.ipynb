{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compact-election",
   "metadata": {},
   "source": [
    "## Creating the model-handler\n",
    "\n",
    "Input interface to models can vary from one to another and therefore Torchserve provides a way to define how the input data sent to the model should be handled to generate the tensors most often needed for your models. This is called the model handler. Torch serve provide the baseclass to write the model handler.\n",
    "\n",
    "Torchserve provides default handlers for image_classifier, image_segmenter, object_detector and text_classifier. It is instructive to read the [code] (https://github.com/pytorch/serve/blob/master/ts/torch_handler) for the these handlers to better understand the mechanism.\n",
    "\n",
    "In this example, we will create a simple handler from scratch for illustration purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-parallel",
   "metadata": {},
   "source": [
    "## Package Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-indonesia",
   "metadata": {},
   "source": [
    "## Build Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-bidder",
   "metadata": {},
   "source": [
    "## Test Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-genome",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "saved-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "project='pytorch-tpu-nfs'\n",
    "staging_bucket='automl-samples'\n",
    "aiplatform.init(project=project, staging_bucket=staging_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "specific-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = 'pt-txt-cls'\n",
    "serving_container_image_uri = 'us-central1-docker.pkg.dev/pytorch-tpu-nfs/pytorch-models/bert-base'\n",
    "artifact_uri = None\n",
    "serving_container_predict_route = '/predictions/bert-base'\n",
    "serving_container_health_route = '/ping'\n",
    "description = \"bert-base finetuned on IMDB\"\n",
    "serving_container_command = None\n",
    "serving_container_args = None\n",
    "serving_container_environment_variables = None\n",
    "serving_container_ports = [7080]\n",
    "instance_schema_uri = None\n",
    "parameters_schema_uri = None\n",
    "prediction_schema_uri = None\n",
    "explanation_metadata = None\n",
    "explanation_parameters = None\n",
    "sync = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ancient-showcase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt-txt-cls\n",
      "projects/64701051322/locations/us-central1/models/7620635927278256128\n"
     ]
    }
   ],
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=display_name,\n",
    "    artifact_uri=artifact_uri,\n",
    "    serving_container_image_uri=serving_container_image_uri,\n",
    "    serving_container_predict_route=serving_container_predict_route,\n",
    "    serving_container_health_route=serving_container_health_route,\n",
    "    serving_container_ports=serving_container_ports,\n",
    "    sync=sync,\n",
    ")\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "literary-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    project=project,\n",
    "    display_name=display_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "other-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = endpoint\n",
    "deployed_model_display_name = display_name\n",
    "machine_type = 'n1-standard-16'\n",
    "min_replica_count = 1\n",
    "max_replica_count = 3\n",
    "sync = sync\n",
    "model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=display_name,\n",
    "        machine_type=machine_type,\n",
    "        min_replica_count=min_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "precise-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample_review.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample_review.txt\n",
    "It was long and boring movie. I could not watch for 5 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "arranged-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "sample_review = 'sample_review.txt'\n",
    "b64_encode = base64.b64encode(open(sample_review, \"rb\").read())\n",
    "instance = {\n",
    "      \"data\": {\n",
    "        \"b64\": str(b64_encode.decode(\"utf-8\"))\n",
    "      }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "split-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict([instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "trying-diversity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=['NOT_HAPPY'], deployed_model_id='7278854936807342080')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
